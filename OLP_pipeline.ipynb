{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLP_LLM: Pipeline for generating FOON graphs via LLM Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 :- Generate a FOON via LLM Prompting\n",
    "\n",
    "1. Initialize libraries needed for FOON (``FOON_graph_analyser.py``) as well as OpenAI api.\n",
    "\n",
    "2. Perform 2-stage prompting for recipe prototype.\n",
    "    - In the first stage, we ask the LLM for a *high-level recipe* (list of instructions) and a *list of objects* needed for completing the recipe.\n",
    "    - In the second stage, we ask the LLM for a breakdown of *state changes* that happen for each step of the recipe; specifically, we ask for the *preconditions* and *effects* of each action, which is similar to how a functional unit in FOON has *input* and *output object nodes*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olp_lib import *\n",
    "\n",
    "# -- use the custom-made class for accessing OpenAI models:\n",
    "openai_driver = OpenAIInterfacer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utamp.driver as driver\n",
    "from utamp.generate import randomize_blocks\n",
    "\n",
    "run_utamp = False\n",
    "\n",
    "if run_utamp:\n",
    "    # -- load the scene only once:\n",
    "    # utamp = driver.UTAMP(scene_file_name='./utamp/scenes/panda_blocks_tiles-5.ttt')\n",
    "\n",
    "    fpath, tally = randomize_blocks('./utamp/scenes/panda_blocks_tiles_prototype.ttt')\n",
    "    utamp = driver.UTAMP(scene_file_name=fpath)\n",
    "\n",
    "    print(\"objects presently in scene:\", utamp.objects_in_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language to  OLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tasks = [\n",
    "\t\"How can I make a Dark and Stormy cocktail?\",\n",
    "\t\"How can I make a Bloody Mary cocktail?\",\n",
    "\t\"How can I make a Greek salad?\",\n",
    "\t\"How can I stack a tower of blocks?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt LLM for Object-level Plan (OLP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_OLP() missing 1 required positional argument: 'openai_obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26492/474113914.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m llm_output = generate_OLP(query=user_task,\n\u001b[0m\u001b[0;32m     14\u001b[0m                                                   \u001b[0mincontext_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mincontext_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                           \u001b[0mstage1_sys_prompt_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./llm_prompts/stage1_system_prompt.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: generate_OLP() missing 1 required positional argument: 'openai_obj'"
     ]
    }
   ],
   "source": [
    "# NOTE: all incontext examples will be stored within a JSON file:\n",
    "# -- Q: can we randomly sample from the set of incontext examples?\n",
    "# -- Q: should we also select an example \"closest\" to the provided task?\n",
    "# incontext_file = \"incontext_examples.txt\"\n",
    "incontext_file = \"incontext_examples.json\"\n",
    "\n",
    "LLM_to_PDDL = True\n",
    "\n",
    "user_task = choice(user_tasks)\n",
    "\n",
    "llm_output = generate_OLP(openai_driver,\n",
    "\t\t\t\t\t\t  query=user_task,\n",
    "\t\t\t\t\t\t  incontext_file=incontext_file,\n",
    "                          stage1_sys_prompt_file=\"./llm_prompts/stage1_system_prompt.txt\",\n",
    "                          stage2_sys_prompt_file=\"./llm_prompts/stage2_system_prompt_v2.txt\",\n",
    "\t\t\t\t\t\t  verbose=False)\n",
    "\n",
    "print('Objects referenced in plan:', llm_output['RelevantObjects'])\n",
    "print('Terminal Steps:', llm_output['TerminalSteps'])\n",
    "\n",
    "# -- save unparsed output to a JSON file:\n",
    "json.dump(llm_output, open('raw_OLP.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TASK:\",  user_task)\n",
    "print(f\"\\n{'*' * 23}\\n    High level plan\\n{'*' * 23}\\n{llm_output['PlanSketch']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***********************\\n   Object level plan\\n***********************\\n\")\n",
    "print(llm_output['OLP'], sep=\"\\n\")\n",
    "print(f\"\\n***********************\\n   Plan objects\\n***********************\\n{llm_output['RelevantObjects']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample FOON creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plan_step, plan_objects = llm_output['OLP'],\n",
    "\n",
    "if '.json' in str(incontext_file).lower():\n",
    "    sample_unit = create_functionalUnit_ver2(llm_output, index=0)\n",
    "else:\n",
    "    sample_unit = create_functionalUnit_ver1(llm_output['OLP'][0]['Instructions'],llm_output['RelevantObjects'])\n",
    "\n",
    "sample_unit.print_functions[2](version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating FOON units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOON_prototype = []\n",
    "\n",
    "for x in range(len(llm_output['OLP']['Instructions'])):\n",
    "\n",
    "    new_unit = create_functionalUnit(llm_output, index=x)\n",
    "\n",
    "    # NOTE: in order to define a macro-problem, we need to properly identify all goal nodes;\n",
    "    #       we will do this with the help of the LLM:\n",
    "    if 'TerminalSteps' in llm_output and (x+1) in llm_output['TerminalSteps']:\n",
    "        # -- set output objects as goal nodes for the functional units deemed as terminal steps:\n",
    "        print(f'\\nFunctional unit {x+1} has terminal goals!')\n",
    "        for N in range(new_unit.getNumberOfOutputs()):\n",
    "            new_unit.getOutputNodes()[N].setAsGoal()\n",
    "\n",
    "    # -- add the functional unit to the FOON prototype:\n",
    "\n",
    "    if not new_unit.isEmpty():\n",
    "        # -- we should only add a new functional unit if it is not empty, meaning it must have the following:\n",
    "        #    1. >=1 input node and >= 1 output node\n",
    "        #    2. a valid motion node\n",
    "        FOON_prototype.append(new_unit)\n",
    "        FOON_prototype[-1].print_functions[-1]()\n",
    "    else:\n",
    "        print('NOTE: the following functional unit has an error, so skipping it:')\n",
    "        new_unit.print_functions[-1]()\n",
    "\n",
    "    print('\\n', '*' * 40)\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LLM_to_PDDL:\n",
    "\n",
    "    pddl_sys_prompt_file = \"llm_prompts/pddl_system_prompt.txt\"\n",
    "\n",
    "    pddl_system_prompt = open(pddl_sys_prompt_file, 'r').read()\n",
    "\n",
    "    message = [{\"role\": \"system\", \"content\": pddl_system_prompt}]\n",
    "\n",
    "    # for x in range(len(OLP_results['OLP']['Instructions'])):\n",
    "    pddl_user_prompt = f\"Generate PDDL for :\\n{llm_output['OLP']['Instructions']}\"\n",
    "\n",
    "    message.extend([{\"role\": \"user\", \"content\": pddl_user_prompt}])\n",
    "\n",
    "    _, response = openai_driver.prompt(prompt=message, verbose=False)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing FOON to a Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file_name = 'prototype.txt'\n",
    "task_file_name = f\"{str.lower(re.compile('[^a-zA-Z]').sub('_', llm_output['OLP']['Query'])[:-1])}.txt\"\n",
    "print(task_file_name)\n",
    "\n",
    "# -- save the prototype FOON graph as a text file, which we will then run with a parser to correct numbering:\n",
    "if not os.path.exists('./preprocess/'):\n",
    "    os.makedirs('./preprocess/')\n",
    "\n",
    "if not os.path.exists('./postprocess/'):\n",
    "    os.makedirs('./postprocess/')\n",
    "\n",
    "temp_file = open(f'./preprocess/{temp_file_name}', 'w')\n",
    "temp_file.write('#\\tFOON Prototype\\n#\\t-- Task Prompt: {0}\\n//\\n'.format(user_task))\n",
    "for unit in FOON_prototype:\n",
    "    unit.print_functions[2]()\n",
    "    temp_file.write(unit.getFunctionalUnitText())\n",
    "    print('//')\n",
    "\n",
    "temp_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse and clean generated FOON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- running parsing module to ensure that FOON labels and IDs are made consistent for further use:\n",
    "#\t\t(it is important that each object and state type have a *UNIQUE* identifier)\n",
    "fpa.skip_JSON_conversion = True\t\t# -- we don't need JSON versions of a FOON\n",
    "fpa.skip_index_check = True\t\t\t# -- always create a new set of index files\n",
    "\n",
    "fpa.source_dir = './preprocess/'\n",
    "fpa.target_dir = './postprocess/'\n",
    "fpa._run_parser()\n",
    "\n",
    "with open(f'./postprocess/{temp_file_name}', 'r') as input_file:\n",
    "    with open(f'./postprocess/{task_file_name}', 'w') as output_file:\n",
    "        for line in input_file:\n",
    "            output_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save generated FOON to embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_embeddings(openai_driver,\n",
    "\t\t\t\t  text=user_task,\n",
    "\t\t\t\t  func_unit=fga.FOON_functionalUnits[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 :- FOON to PDDL\n",
    "1. Parse FOON file -- this step is important to ensure that all labels are unique and that the generated file follows the FOON syntax.\n",
    "\n",
    "2. (Optional) Visualize FOON graph\n",
    "\n",
    "3. Run ``FOON_to_PDDL.py`` script to generate FOON macro-operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Run FOON visualization tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- after running the parser, take the 'prototype.txt' file and plot it using the following tool: https://davidpaulius.github.io/foon-view/\n",
    "# fga._startFOONview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PDDL files using ```FOON_to_PDDL``` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FOON_TAMP as fta\n",
    "from pathlib import Path\n",
    "\n",
    "FOON_subgraph_file = f'./postprocess/{task_file_name}'\n",
    "\n",
    "# -- definition of macro and micro plan file names:\n",
    "macro_plan_file = os.path.splitext(FOON_subgraph_file)[0] + '_macro.plan'\n",
    "micro_plan_file = os.path.splitext(FOON_subgraph_file)[0] + '_micro.plan'\n",
    "\n",
    "fta.micro_domain_file = './FOON_skills.pddl'\n",
    "\n",
    "fta.flag_perception = False\n",
    "\n",
    "# -- create a new folder for the generated problem files and their corresponding plans:\n",
    "fta.micro_problems_dir = './micro_problems-' + Path(FOON_subgraph_file).stem\n",
    "if not os.path.exists(fta.micro_problems_dir):\n",
    "    os.makedirs(fta.micro_problems_dir)\n",
    "\n",
    "ftp = fta.ftp\n",
    "\n",
    "# -- perform conversion of the FOON subgraph file to PDDL:\n",
    "ftp.FOON_subgraph_file = FOON_subgraph_file\n",
    "ftp._convert_to_PDDL('OCP')\n",
    "\n",
    "## -- parse through the newly created domain file and find all (macro) planning operators:\n",
    "all_macro_POs = {PO.name : PO for PO in fta._parseDomainPDDL(ftp.FOON_domain_file)}\n",
    "\n",
    "# -- checking to see if a macro level plan has been found (FD allows exporting to a file):\n",
    "outcome = fta._findPlan(\n",
    "    domain_file=ftp.FOON_domain_file,   # NOTE: FOON_to_PDDL object will already contain the names of the\n",
    "    problem_file=ftp.FOON_problem_file,  #   corresponding macro-level domain and problem files\n",
    "    output_plan_file=macro_plan_file\n",
    ")\n",
    "\n",
    "# TODO: write planning pipeline for other planners?\n",
    "\n",
    "complete_micro_plan = []\n",
    "\n",
    "if fta._checkPlannerOutput(output=outcome):\n",
    "    print(\"  -- [FOON-TAMP] : A macro-level plan for '\" + str(FOON_subgraph_file) + \"' was found!\")\n",
    "\n",
    "    # -- now that we have a plan, we are going to parse it for the steps:\n",
    "    macro_file = open(macro_plan_file, 'r')\n",
    "\n",
    "    # NOTE: counters for macro- and micro-level steps:\n",
    "    macro_count, micro_count = 0, 0\n",
    "\n",
    "    macro_plan_lines = list(macro_file)\n",
    "    for L in macro_plan_lines:\n",
    "        if L.startswith('('):\n",
    "            print('\\t\\t\\t' + str(macro_count) + ' : ' + L.strip())\n",
    "    print()\n",
    "\n",
    "    for L in range(len(macro_plan_lines)):\n",
    "\n",
    "        if macro_plan_lines[L].startswith('('):\n",
    "            # NOTE: this is where we have identified a macro plan's step; here, we check the contents of its PO definition for:\n",
    "            #\t1. preconditions - this will become a sub-problem file's initial states (as predicates)\n",
    "            #\t2. effects - this will become a sub-problem file's goal states (as predicates)\n",
    "\n",
    "            macro_count += 1\n",
    "\n",
    "            macro_PO_name = macro_plan_lines[L][1:-2].strip()\n",
    "\n",
    "            print(\" -- [FOON-TAMP] : Searching for micro-level plan for '\" + macro_PO_name + \"' macro-PO...\")\n",
    "\n",
    "            # -- try to find this step's matching planning operator definition:\n",
    "            matching_PO_obj = all_macro_POs[macro_PO_name] if macro_PO_name in all_macro_POs else None\n",
    "\n",
    "            # -- when we find the equivalent planning operator, then we proceed to treat it as its own problem:\n",
    "            if matching_PO_obj:\n",
    "                # -- create sub-problem file (i.e., at the micro-level):\n",
    "                micro_problem_file = fta._defineMicroProblem(\n",
    "                    macro_PO_name,\n",
    "                    preconditions=matching_PO_obj.getPreconditions(),\n",
    "                    effects=matching_PO_obj.getEffects(),\n",
    "                )\n",
    "\n",
    "                micro_domain_file = fta._defineMicroDomain(\n",
    "                    preconditions=matching_PO_obj.getPreconditions(),\n",
    "                )\n",
    "\n",
    "                complete_micro_plan.append('; step ' + str(macro_count) + ' -- (' + macro_PO_name + '):')\n",
    "\n",
    "                need_to_replan = False\n",
    "\n",
    "                # -- try to find a sub-problem plan / solution:\n",
    "                outcome = fta._findPlan(\n",
    "                    domain_file=micro_domain_file,\n",
    "                    problem_file=micro_problem_file,\n",
    "                    output_plan_file=str(fta.micro_problems_dir + '/' + macro_PO_name + '_micro.plan')\n",
    "                )\n",
    "\n",
    "                print('\\n\\t' + 'step ' + str(macro_count) +' -- (' + macro_PO_name + ')')\n",
    "\n",
    "                if fta._checkPlannerOutput(outcome):\n",
    "\n",
    "                    print('\\t\\t -- micro-level plan found as follows:')\n",
    "\n",
    "                    # -- open the micro problem file, read each line referring to a micro PO, and save to list:\n",
    "                    micro_file = open(\n",
    "                        str(fta.micro_problems_dir + '/' + macro_PO_name + '_micro.plan'), 'r')\n",
    "\n",
    "                    # -- all except for the last line should be valid steps:\n",
    "                    micro_file_lines = []\n",
    "                    count = 0\n",
    "\n",
    "                    for micro_line in micro_file:\n",
    "                        if micro_line.startswith('('):\n",
    "                            # -- parse the line and remove trailing newline character:\n",
    "                            micro_step = micro_line.strip()\n",
    "                            micro_file_lines.append(micro_step)\n",
    "\n",
    "                            # -- print entire plan to the command line in format of X.Y,\n",
    "                            #       where X is the macro-step count and Y is the micro-step count:\n",
    "                            count += 1\n",
    "                            print('\\t\\t\\t' + str(macro_count) + '.' + str(count) + ' : ' + micro_step)\n",
    "                        #endif\n",
    "                    #endfor\n",
    "        print()\n",
    "else:\n",
    "    print(\"  -- [FOON-TAMP] : A macro-level plan for '\" + str(FOON_subgraph_file) + \"' was NOT found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_micro_plan = []\n",
    "\n",
    "# -- we can also perform a search where we assume we already have a task tree\n",
    "#\t\tand we execute each functional unit one by one as we see\n",
    "\n",
    "macro_plan_lines = []\n",
    "for N in range(len(ftp.fga.FOON_lvl3)):\n",
    "    PO_name = f'{ftp._reviseObjectLabels(ftp.fga.FOON_lvl3[N].getMotion().getMotionLabel())}_{N}'\n",
    "    macro_plan_lines.append(PO_name)\n",
    "\n",
    "macro_count = 0\n",
    "\n",
    "for L in range(len(macro_plan_lines)):\n",
    "\n",
    "    macro_count += 1\n",
    "\n",
    "    macro_PO_name = macro_plan_lines[L]\n",
    "\n",
    "    print(\" -- [FOON-TAMP] : Searching for micro-level plan for '\" + macro_PO_name + \"' macro-PO...\")\n",
    "\n",
    "    # -- try to find this step's matching planning operator definition:\n",
    "    matching_PO_obj = all_macro_POs[macro_PO_name] if macro_PO_name in all_macro_POs else None\n",
    "\n",
    "    # -- when we find the equivalent planning operator, then we proceed to treat it as its own problem:\n",
    "    if matching_PO_obj:\n",
    "        # -- create sub-problem file (i.e., at the micro-level):\n",
    "        micro_problem_file = fta._defineMicroProblem(\n",
    "            macro_PO_name,\n",
    "            preconditions=matching_PO_obj.getPreconditions(),\n",
    "            effects=matching_PO_obj.getEffects(),\n",
    "        )\n",
    "\n",
    "        micro_domain_file = fta._defineMicroDomain(\n",
    "            preconditions=matching_PO_obj.getPreconditions(),\n",
    "        )\n",
    "\n",
    "        complete_micro_plan.append('; step ' + str(macro_count) + ' -- (' + macro_PO_name + '):')\n",
    "\n",
    "        need_to_replan = False\n",
    "\n",
    "        # -- try to find a sub-problem plan / solution:\n",
    "        outcome = fta._findPlan(\n",
    "            domain_file=micro_domain_file,\n",
    "            problem_file=micro_problem_file,\n",
    "            output_plan_file=str(fta.micro_problems_dir + '/' + macro_PO_name + '_micro.plan')\n",
    "        )\n",
    "\n",
    "        print('\\n\\t' + 'step ' + str(macro_count) +' -- (' + macro_PO_name + ')')\n",
    "\n",
    "        if fta._checkPlannerOutput(outcome):\n",
    "\n",
    "            print('\\t\\t -- micro-level plan found as follows:')\n",
    "\n",
    "            # -- open the micro problem file, read each line referring to a micro PO, and save to list:\n",
    "            micro_file = open(\n",
    "                str(fta.micro_problems_dir + '/' + macro_PO_name + '_micro.plan'), 'r')\n",
    "\n",
    "            # -- all except for the last line should be valid steps:\n",
    "            micro_file_lines = []\n",
    "            count = 0\n",
    "\n",
    "            for micro_line in micro_file:\n",
    "                if micro_line.startswith('('):\n",
    "                    # -- parse the line and remove trailing newline character:\n",
    "                    micro_step = micro_line.strip()\n",
    "                    micro_file_lines.append(micro_step)\n",
    "\n",
    "                    # -- print entire plan to the command line in format of X.Y,\n",
    "                    #       where X is the macro-step count and Y is the micro-step count:\n",
    "                    count += 1\n",
    "                    print('\\t\\t\\t' + str(macro_count) + '.' + str(count) + ' : ' + micro_step)\n",
    "                #endif\n",
    "            #endfor\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Connection with UTAMP System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_utamp = False\n",
    "\n",
    "if run_utamp:\n",
    "    # -- now that we have a plan, we are going to parse it for the steps:\n",
    "    macro_file = open(macro_plan_file, 'r')\n",
    "\n",
    "    # NOTE: counters for macro- and micro-level steps:\n",
    "    macro_count, micro_count = 0, 0\n",
    "\n",
    "    # macro_plan_lines = list(macro_file)\n",
    "    # for L in macro_plan_lines:\n",
    "    #     if L.startswith('('):\n",
    "    #         print('\\t' + str(macro_count) + ' : ' + L.strip())\n",
    "    #         macro_count += 1\n",
    "\n",
    "    macro_plan_lines = []\n",
    "    for N in range(len(ftp.fga.FOON_lvl3)):\n",
    "        PO_name = f'{ftp._reviseObjectLabels(ftp.fga.FOON_lvl3[N].getMotion().getMotionLabel())}_{N}'\n",
    "        # print('\\t' + str(macro_count) + ' : ' + PO_name)\n",
    "        macro_plan_lines.append(PO_name)\n",
    "\n",
    "    macro_count = 0\n",
    "\n",
    "    total_success = 0\n",
    "\n",
    "    for L in range(len(macro_plan_lines)):\n",
    "        # NOTE: this is where we have identified a macro plan's step; here, we check the contents of its PO definition for:\n",
    "        #\t1. preconditions - this will become a sub-problem file's initial states (as predicates)\n",
    "        #\t2. effects - this will become a sub-problem file's goal states (as predicates)\n",
    "\n",
    "        macro_count += 1\n",
    "\n",
    "        # macro_PO_name = macro_plan_lines[L][1:-2].strip()\n",
    "        macro_PO_name = macro_plan_lines[L]\n",
    "\n",
    "        print(\" -- [FOON-TAMP] : Searching for micro-level plan for '\" + macro_PO_name + \"' macro-PO...\")\n",
    "\n",
    "        # -- try to find this step's matching planning operator definition:\n",
    "        matching_PO_obj = all_macro_POs[macro_PO_name] if macro_PO_name in all_macro_POs else None\n",
    "\n",
    "        # -- when we find the equivalent planning operator, then we proceed to treat it as its own problem:\n",
    "        if matching_PO_obj:\n",
    "            # -- create sub-problem file (i.e., at the micro-level):\n",
    "            micro_problem_file = fta._defineMicroProblem(\n",
    "                macro_PO_name,\n",
    "                preconditions=matching_PO_obj.getPreconditions(),\n",
    "                effects=matching_PO_obj.getEffects(),\n",
    "            )\n",
    "\n",
    "            complete_micro_plan.append('; step ' + str(macro_count) + ' -- (' + macro_PO_name + '):')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        goal_preds, objects_in_OLP = [], []\n",
    "\n",
    "        # -- parse the goals in the generated micro-problem file:\n",
    "        micro_problem_lines = open(micro_problem_file, 'r').readlines()\n",
    "        for M in range(len(micro_problem_lines)):\n",
    "            if (\"(:goal\" in micro_problem_lines[M]):\n",
    "                while True:\n",
    "                    M += 1\n",
    "\n",
    "                    if micro_problem_lines[M].startswith(\"))\"):\n",
    "                        break\n",
    "\n",
    "                    goal_string = str(micro_problem_lines[M]).replace(\"\\t\", \"\").strip()\n",
    "                    if goal_string:\n",
    "                        # -- first, we check if a goal string line is actually referring to a comment or a negation predicate:\n",
    "                        if goal_string.startswith(\";\") or goal_string.startswith(\"(not\"):\n",
    "                            # -- we want to skip those:\n",
    "                            continue\n",
    "\n",
    "                        # -- append the goal string to the list of goal predicates:\n",
    "                        goal_preds.append(goal_string)\n",
    "\n",
    "                        # -- we also want to parse the goal string to identify all possible expressions for objects at the object level:\n",
    "                        predicate_args = goal_preds[-1][1:-1].split(\" \")\n",
    "                        objects_in_OLP.extend([predicate_args[x] for x in range(1, len(predicate_args))])\n",
    "                #endwhile\n",
    "            #endif\n",
    "        #endfor\n",
    "\n",
    "        # print(\"objects in OLP:\", objects_in_OLP)\n",
    "\n",
    "        assert bool(goal_preds), f\"Error: empty list of goals! Check the generated micro-problem file '{micro_problem_file}'\"\n",
    "\n",
    "        # -- prompt LLMs to perform object grounding\n",
    "        #       (remove any objects that do not require grounding -- these are handled by the task planner system):\n",
    "        objects_in_OLP = list(set(objects_in_OLP) - set(['hand', 'air', 'table', 'robot']))\n",
    "\n",
    "        message = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Assign each of these simulation objects to real-world objects. You may only assign each object once.\"\n",
    "                    \" Give your output as a Python dictionary.\"\n",
    "                    f\"\\nReal-world object: {objects_in_OLP}\"\n",
    "                    f\"\\nSimulated objects: {utamp.objects_in_sim}\"\n",
    "                    \"\\nExample: {'object_1': 'sim_object_1', 'object_2': 'sim_object_2'}\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        _, response = prompt_LLM(message, selected_LLM)\n",
    "        # print(\"LLM response:\", response)\n",
    "        regex_matches = re.findall(r'\\{.+\\}', str(eval(response)))\n",
    "\n",
    "        if bool(regex_matches):\n",
    "            # -- this means that the LLM has proposed some object groundings for us:\n",
    "            obj_grounding = eval(regex_matches.pop())\n",
    "            print(obj_grounding)\n",
    "\n",
    "            # -- parse the goal predicates and replace the generic object names with those of the sim objects:\n",
    "            print(\"before grounding:\", goal_preds)\n",
    "            for G in range(len(goal_preds)):\n",
    "                goal_pred_parts = goal_preds[G][1:-1].split(\" \")\n",
    "                for obj in goal_pred_parts[1:]:\n",
    "                    if obj in obj_grounding:\n",
    "                        goal_preds[G] = goal_preds[G].replace(obj, obj_grounding[obj])\n",
    "\n",
    "            print(\"after grounding:\", goal_preds)\n",
    "\n",
    "        success = driver.main(utamp, goal_preds=goal_preds)\n",
    "\n",
    "        total_success += int(success)\n",
    "\n",
    "    # utamp.pause()\n",
    "\n",
    "    print('\\n\\n% Successful:', total_success / macro_count * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: LLM-as-Planner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utamp.stop()\n",
    "\n",
    "if run_utamp:\n",
    "    utamp = driver.UTAMP(scene_file_name=fpath)\n",
    "\n",
    "    print(\"objects presently in scene:\", utamp.objects_in_sim)\n",
    "\n",
    "    # -- use the LLM as a planner to acquire a task plan:\n",
    "\n",
    "    # -- we are going to feed the LLM with the prompt of coming up with a plan using the pre-defined skills:\n",
    "    llm_planner_sys_prompt = open('llm_prompts/llm_planner_system_prompt_2.txt', 'r').read()\n",
    "    message = [{\"role\": \"system\", \"content\": llm_planner_sys_prompt}]\n",
    "\n",
    "    llm_planner_user_prompt = f\"Generate a PDDL task plan for the following task: {user_task} \"\\\n",
    "        f\"The current state of the robot's environment is provided as the following dictionary: {utamp.perform_sensing(method=-1)}.\"\n",
    "\n",
    "    print(llm_planner_user_prompt)\n",
    "\n",
    "    message.extend([{\"role\": \"user\", \"content\": llm_planner_user_prompt}])\n",
    "    print()\n",
    "\n",
    "    _, response = prompt_LLM(given_prompt=message, model_name=openai_models[-1], verbose=False)\n",
    "    print(response)\n",
    "\n",
    "    step_count = 0\n",
    "    steps = response.split('\\n')\n",
    "\n",
    "    goals_per_step = []\n",
    "    parsed_steps = []\n",
    "\n",
    "    while True:\n",
    "        step_count += 1\n",
    "\n",
    "        found = False\n",
    "\n",
    "        for x in range(len(steps)):\n",
    "            if steps[x].startswith(f\"{step_count}.\"):\n",
    "\n",
    "                found = True\n",
    "\n",
    "                step_parts = steps[x].split('(')[1].split(')')[0]\n",
    "                action, args = step_parts.split(' ')[0], step_parts.split(' ')[1:]\n",
    "\n",
    "                tokenized_step = step_parts.split(' ')\n",
    "\n",
    "                parsed_steps.append(tokenized_step)\n",
    "\n",
    "                if 'place' in action or 'stack' in action:\n",
    "                    goals_per_step.append([\n",
    "                        f\"(on {args[0]} air)\",\n",
    "                        f\"(under {args[0]} {args[1]})\",\n",
    "                        f\"(on {args[1]} {args[0]})\",\n",
    "                    ])\n",
    "\n",
    "        if not found:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script --no-raise-error false\n",
    "\n",
    "if run_utamp:\n",
    "    print(len(goals_per_step))\n",
    "\n",
    "    total_success = 0\n",
    "    for x in goals_per_step:\n",
    "        success = driver.main(utamp, goal_preds=x)\n",
    "        total_success += int(success)\n",
    "\n",
    "    print('\\n\\n% Successful:', total_success / (step_count-1) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_utamp:\n",
    "    utamp.start()\n",
    "\n",
    "    total_success = 0\n",
    "\n",
    "    for step in parsed_steps:\n",
    "        close_gripper, target_object = None, None\n",
    "        if 'pick' in step[0]:\n",
    "            close_gripper = 1\n",
    "        else:\n",
    "            close_gripper = 0\n",
    "        target_object = step[-1]\n",
    "\n",
    "        success = utamp.path_planning(\n",
    "            target_object=target_object,\n",
    "            gripper_action=close_gripper)\n",
    "\n",
    "        total_success += int(success)\n",
    "\n",
    "    print('\\n\\n% Successful:', total_success / (step_count-1) * 100.0)\n",
    "\n",
    "    utamp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%script --no-raise-error false\n",
    "utamp.start()\n",
    "utamp.path_planning(\n",
    "\ttarget_object='red_block_2',\n",
    "\tgripper_action=1,\n",
    "\talgorithm='PRMstar')\n",
    "\n",
    "utamp.path_planning(\n",
    "\ttarget_object='green_block_2',\n",
    "\tgripper_action=0,\n",
    "\talgorithm='PRMstar')\n",
    "\n",
    "utamp.path_planning(\n",
    "\ttarget_object='green_block_3',\n",
    "\tgripper_action=1,\n",
    "\talgorithm='PRMstar')\n",
    "\n",
    "utamp.path_planning(\n",
    "\ttarget_object='red_block_2',\n",
    "\tgripper_action=0,\n",
    "\talgorithm='PRMstar')\n",
    "\n",
    "utamp.path_planning(\n",
    "\ttarget_object='yellow_block_1',\n",
    "\tgripper_action=1,\n",
    "\talgorithm='PRMstar')\n",
    "\n",
    "utamp.path_planning(\n",
    "\ttarget_object='yellow_tile',\n",
    "\tgripper_action=0,\n",
    "\talgorithm='PRMstar')\n",
    "\n",
    "utamp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olp_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
